{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf95237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(sys.path[0] + \"/..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493fbb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import properties\n",
    "import pymysql\n",
    "import random\n",
    "import utils\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b00d602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b270613",
   "metadata": {},
   "source": [
    "### FEVER data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5db21243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEVER Wikipedia DB\n",
    "\n",
    "mysql_host = os.getenv(\"HOST\", \"localhost\")\n",
    "mysql_port = int(os.getenv(\"PORT\", \"3306\"))\n",
    "mysql_user = os.getenv(\"USER\", \"root\")\n",
    "mysql_pass = os.getenv(\"PASS\", \"DimeMP01!\")\n",
    "mysql_db = os.getenv(\"DB\", \"fever\")\n",
    "\n",
    "conn = pymysql.connect(host=\"localhost\", port=3306, user=\"root\", password=\"DimeMP01!\", db=\"fever\")\n",
    "CUR = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ab7580b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_wiki_evidence(wiki_id: str, sent_idx: int) -> str:\n",
    "    query = \"SELECT * FROM fever.wiki_pages where id='{}'\".format(wiki_id)\n",
    "    CUR.execute(query)\n",
    "    \n",
    "    try:\n",
    "        entry = next(CUR)\n",
    "        texts = entry[1].split(\"\\n\")\n",
    "        text = texts[sent_idx].split(\"\\t\")[1]\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(\"No entry in wiki database for id = {}\".format(wiki_id))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5d0f6aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Snakebite is the first official release by the British hard rock band Whitesnake .'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_wiki_evidence(\"Snakebite_-LRB-album-RRB-\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c786fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_wiki_db(wiki_db_path = \"/Users/user/Downloads/wiki-pages/wiki-pages-jsons\"):\n",
    "    wiki_entries = {}\n",
    "    for file in os.listdir(wiki_db_path):\n",
    "        with open(os.path.join(wiki_db_path, file)) as f:\n",
    "            entry = json.load(f)\n",
    "            wiki_entries[entry['id']] = entry['lines']\n",
    "            \n",
    "    return wiki_entries\n",
    "\n",
    "# wiki_db = _load_wiki_db()\n",
    "wiki_db = pd.read_csv(\"/Users/user/Downloads/wiki-pages/wiki-pages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b1c94df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Snakebite_-LRB-album-RRB-</td>\n",
       "      <td>Snakebite is the first official release by the...</td>\n",
       "      <td>0\\tSnakebite is the first official release by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sin_Sukju</td>\n",
       "      <td>Sin Suk-ju -LRB- Korean : 신숙주 , hanja : 申叔舟 ; ...</td>\n",
       "      <td>0\\tSin Suk-ju -LRB- Korean : 신숙주 , hanja : 申叔舟...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>South_Oroville,_California</td>\n",
       "      <td>South Oroville is a census-designated place -L...</td>\n",
       "      <td>0\\tSouth Oroville is a census-designated place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Southwest_Golf_Classic</td>\n",
       "      <td>The Southwest Golf Classic was a PGA Tour even...</td>\n",
       "      <td>0\\tThe Southwest Golf Classic was a PGA Tour e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>St._Philip's_Cathedral,_San_Felipe</td>\n",
       "      <td>The St. Philip 's Cathedral -LRB- Catedral de ...</td>\n",
       "      <td>0\\tThe St. Philip 's Cathedral -LRB- Catedral ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  id  \\\n",
       "0           0           Snakebite_-LRB-album-RRB-   \n",
       "1           1                           Sin_Sukju   \n",
       "2           2          South_Oroville,_California   \n",
       "3           3              Southwest_Golf_Classic   \n",
       "4           4  St._Philip's_Cathedral,_San_Felipe   \n",
       "\n",
       "                                                text  \\\n",
       "0  Snakebite is the first official release by the...   \n",
       "1  Sin Suk-ju -LRB- Korean : 신숙주 , hanja : 申叔舟 ; ...   \n",
       "2  South Oroville is a census-designated place -L...   \n",
       "3  The Southwest Golf Classic was a PGA Tour even...   \n",
       "4  The St. Philip 's Cathedral -LRB- Catedral de ...   \n",
       "\n",
       "                                               lines  \n",
       "0  0\\tSnakebite is the first official release by ...  \n",
       "1  0\\tSin Suk-ju -LRB- Korean : 신숙주 , hanja : 申叔舟...  \n",
       "2  0\\tSouth Oroville is a census-designated place...  \n",
       "3  0\\tThe Southwest Golf Classic was a PGA Tour e...  \n",
       "4  0\\tThe St. Philip 's Cathedral -LRB- Catedral ...  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "4e1cc69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1839206</th>\n",
       "      <td>1839206</td>\n",
       "      <td>Selena</td>\n",
       "      <td>Selena Quintanilla-Pérez -LRB- -LSB- seˈlena k...</td>\n",
       "      <td>0\\tSelena Quintanilla-Pérez -LRB- -LSB- seˈlen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      id  \\\n",
       "1839206     1839206  Selena   \n",
       "\n",
       "                                                      text  \\\n",
       "1839206  Selena Quintanilla-Pérez -LRB- -LSB- seˈlena k...   \n",
       "\n",
       "                                                     lines  \n",
       "1839206  0\\tSelena Quintanilla-Pérez -LRB- -LSB- seˈlen...  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry = wiki_db[wiki_db.id==\"Selena\"]\n",
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "94018768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fever training data\n",
    "fever_train_path = \"/Users/user/Library/CloudStorage/OneDrive-King'sCollegeLondon/PycharmProjects/fc-evidence-evaluation/data/fever/paper_train.jsonl\"\n",
    "train = utils.load_jsonl_file(fever_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "9ee92a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 75397,\n",
       " 'verifiable': 'VERIFIABLE',\n",
       " 'label': 'SUPPORTS',\n",
       " 'claim': 'Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.',\n",
       " 'evidence': [[[92206, 104971, 'Nikolaj_Coster-Waldau', 7],\n",
       "   [92206, 104971, 'Fox_Broadcasting_Company', 0]]]}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "train[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8898dda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[92206, 104971, 'Nikolaj_Coster-Waldau', 7],\n",
       "  [92206, 104971, 'Fox_Broadcasting_Company', 0]]]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train[index]['evidence']))\n",
    "train[index]['evidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a287b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter entries with more than one evidence set\n",
    "train_multi_evidence = [entry for entry in train if len(entry['evidence'])>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "4db9aae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial entries: 145449\n",
      "Entries with more than one evidence sets: 30972\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial entries: {}\".format(len(train)))\n",
    "print(\"Entries with more than one evidence sets: {}\".format(len(train_multi_evidence)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d654d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_SAMPLE = {\n",
    "    \"claim\": \"\",\n",
    "    \"reference\": \"\",\n",
    "    \"target\": \"\",\n",
    "    \"score\": 1,\n",
    "    \"label\": None\n",
    "}\n",
    "_EVIDENCE_FORMAT = \"Title: {}; {}\"\n",
    "\n",
    "def _get_wiki_evidence(wiki_id: str, sentence_idx: int): \n",
    "    entry = wiki_db[wiki_db.id==wiki_id]\n",
    "    sentences = list(entry.to_dict()[\"lines\"].values())[0]\n",
    "    sentence = sentences.split(\"\\n\")[sentence_idx]\n",
    "    return sentence.split(\"\\t\")[1]\n",
    "    \n",
    "\n",
    "def _get_evidence_text(evidence_set: list):\n",
    "    evidence_text = []\n",
    "    for evidence in evidence_set:\n",
    "        sentence = _get_wiki_evidence(evidence[2], evidence[3])\n",
    "        evidence_text.append(_EVIDENCE_FORMAT.format(evidence[2], sentence))\n",
    "        \n",
    "    return \" \".join(evidence_text)\n",
    "\n",
    "def _format_claim_evidence(claim, evidence_set):\n",
    "    return claim + \" \" + _get_evidence_text(evidence_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a55683a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 150448,\n",
       " 'verifiable': 'VERIFIABLE',\n",
       " 'label': 'SUPPORTS',\n",
       " 'claim': 'Roman Atwood is a content creator.',\n",
       " 'evidence': [[[174271, 187498, 'Roman_Atwood', 1]],\n",
       "  [[174271, 187499, 'Roman_Atwood', 3]]]}"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_multi_evidence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "284e2622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 150448,\n",
       "  'verifiable': 'VERIFIABLE',\n",
       "  'label': 'SUPPORTS',\n",
       "  'claim': 'Roman Atwood is a content creator.',\n",
       "  'evidence': [[[174271, 187498, 'Roman_Atwood', 1]],\n",
       "   [[174271, 187499, 'Roman_Atwood', 3]]]},\n",
       " {'id': 33078,\n",
       "  'verifiable': 'VERIFIABLE',\n",
       "  'label': 'SUPPORTS',\n",
       "  'claim': 'The Boston Celtics play their home games at TD Garden.',\n",
       "  'evidence': [[[49158, 58489, 'Boston_Celtics', 3]],\n",
       "   [[49159, 58490, 'Boston_Celtics', 3]]]},\n",
       " {'id': 6744,\n",
       "  'verifiable': 'VERIFIABLE',\n",
       "  'label': 'SUPPORTS',\n",
       "  'claim': 'The Ten Commandments is an epic film.',\n",
       "  'evidence': [[[23513, 28977, 'The_Ten_Commandments_-LRB-1956_film-RRB-', 0]],\n",
       "   [[23513, 28978, 'The_Ten_Commandments_-LRB-1956_film-RRB-', 20]]]},\n",
       " {'id': 76253,\n",
       "  'verifiable': 'VERIFIABLE',\n",
       "  'label': 'SUPPORTS',\n",
       "  'claim': 'There is a movie called The Hunger Games.',\n",
       "  'evidence': [[[93100, 106004, 'The_Hunger_Games_-LRB-film-RRB-', 0]],\n",
       "   [[93100, 106005, 'The_Hunger_Games_-LRB-film-RRB-', 1]],\n",
       "   [[93100, 106006, 'The_Hunger_Games_-LRB-film-RRB-', 2]],\n",
       "   [[93100, 106007, 'The_Hunger_Games_-LRB-film-RRB-', 16]]]},\n",
       " {'id': 129983,\n",
       "  'verifiable': 'VERIFIABLE',\n",
       "  'label': 'SUPPORTS',\n",
       "  'claim': 'Ryan Seacrest is a person.',\n",
       "  'evidence': [[[152194, 166969, 'Ryan_Seacrest', 0]],\n",
       "   [[152194, 166970, 'Ryan_Seacrest', 1]],\n",
       "   [[152194, 166971, 'Ryan_Seacrest', 2]],\n",
       "   [[152194, 166972, 'Ryan_Seacrest', 5]]]},\n",
       " {'id': 93956,\n",
       "  'verifiable': 'VERIFIABLE',\n",
       "  'label': 'SUPPORTS',\n",
       "  'claim': 'Selena recorded music.',\n",
       "  'evidence': [[[275618, 270725, 'Selena', 8]],\n",
       "   [[275618, 270726, 'Selena', 0]],\n",
       "   [[275618, 270727, 'Selena', 2]],\n",
       "   [[275618, 270728, 'Selena', 4]],\n",
       "   [[277400, 272314, 'Selena', 8]],\n",
       "   [[277400, 272315, 'Selena', 21]],\n",
       "   [[277903, 272835, 'Selena', 0]],\n",
       "   [[277903, 272836, 'Selena', 9]],\n",
       "   [[277903, 272837, 'Selena', 10]],\n",
       "   [[277903, 272838, 'Selena', 11]],\n",
       "   [[277903, 272839, 'Selena', 14]],\n",
       "   [[277903, 272840, 'Selena', 16]],\n",
       "   [[277903, 272841, 'Selena', 18]],\n",
       "   [[277903, 272842, 'Selena', 19]],\n",
       "   [[277903, 272843, 'Selena', 21]],\n",
       "   [[277903, 272844, 'Selena', 32]]]},\n",
       " {'id': 228271,\n",
       "  'verifiable': 'VERIFIABLE',\n",
       "  'label': 'SUPPORTS',\n",
       "  'claim': 'The Silence of the Lambs was a film starring Scott Glenn.',\n",
       "  'evidence': [[[272337,\n",
       "     268022,\n",
       "     'The_Silence_of_the_Lambs_-LRB-film-RRB-',\n",
       "     0]],\n",
       "   [[272346, 268030, 'The_Silence_of_the_Lambs_-LRB-film-RRB-', 0]]]},\n",
       " {'id': 15812,\n",
       "  'verifiable': 'VERIFIABLE',\n",
       "  'label': 'REFUTES',\n",
       "  'claim': 'Peggy Sue Got Married is a Egyptian film released in 1986.',\n",
       "  'evidence': [[[31205, 37902, 'Peggy_Sue_Got_Married', 0],\n",
       "    [31205, 37902, 'Francis_Ford_Coppola', 0]],\n",
       "   [[31211, 37908, 'Peggy_Sue_Got_Married', 0]]]},\n",
       " {'id': 214706,\n",
       "  'verifiable': 'VERIFIABLE',\n",
       "  'label': 'SUPPORTS',\n",
       "  'claim': 'Tupac Shakur was born Lesane Parish Crooks.',\n",
       "  'evidence': [[[254927, 254471, 'Tupac_Shakur', 0]],\n",
       "   [[254931, 254481, 'Tupac_Shakur', 0]]]},\n",
       " {'id': 170685,\n",
       "  'verifiable': 'VERIFIABLE',\n",
       "  'label': 'SUPPORTS',\n",
       "  'claim': 'Lisbon has a population larger than 1.',\n",
       "  'evidence': [[[196930, 206999, 'Lisbon', 0]],\n",
       "   [[196930, 207000, 'Lisbon', 2]]]}]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_multi_evidence[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "0d4f448c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x7/b6tgwcrn1rz_zffbw59v8crr0000gp/T/ipykernel_23279/900766612.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"evidence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_claim_evidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'claim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"evidence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_claim_evidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'claim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"evidence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/x7/b6tgwcrn1rz_zffbw59v8crr0000gp/T/ipykernel_23279/3835499284.py\u001b[0m in \u001b[0;36m_format_claim_evidence\u001b[0;34m(claim, evidence_set)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_format_claim_evidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclaim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevidence_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mclaim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_get_evidence_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevidence_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/x7/b6tgwcrn1rz_zffbw59v8crr0000gp/T/ipykernel_23279/3835499284.py\u001b[0m in \u001b[0;36m_get_evidence_text\u001b[0;34m(evidence_set)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mevidence_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mevidence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevidence_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_wiki_evidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevidence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevidence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mevidence_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_EVIDENCE_FORMAT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevidence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/x7/b6tgwcrn1rz_zffbw59v8crr0000gp/T/ipykernel_23279/3835499284.py\u001b[0m in \u001b[0;36m_get_wiki_evidence\u001b[0;34m(wiki_id, sentence_idx)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_wiki_evidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwiki_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwiki_db\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwiki_db\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mwiki_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lines\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/averitec/lib/python3.9/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/averitec/lib/python3.9/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/averitec/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5622\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5623\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5625\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/averitec/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/averitec/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# prepare training set of POSITIVE samples (similarity score == 1)\n",
    "bleurt_training_data = []\n",
    "\n",
    "for entry in train_multi_evidence: \n",
    "    try:\n",
    "        claim = entry['claim']\n",
    "        targets = []\n",
    "\n",
    "        for i in range(len(entry[\"evidence\"])-1):\n",
    "            reference = _format_claim_evidence(entry['claim'], entry[\"evidence\"][i])\n",
    "            target = _format_claim_evidence(entry['claim'], entry[\"evidence\"][i+1])\n",
    "            if target != reference:\n",
    "                new_entry = POS_SAMPLE.copy()\n",
    "                new_entry['claim'] = entry['claim']\n",
    "                new_entry['reference'] = reference\n",
    "                new_entry['target'] = target\n",
    "                new_entry['label'] = entry['label']\n",
    "                bleurt_training_data.append(new_entry)\n",
    "    except Exception as e: \n",
    "#         print(\"Exception for claim: {}\".format(claim))\n",
    "        continue\n",
    "\n",
    "print(\"For {} multi evidence entries, {} bleurt training samples created\".format(len(train_multi_evidence), \n",
    "                                                                                 len(bleurt_training_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "54bb281b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9618 negative bleurt training samples created\n"
     ]
    }
   ],
   "source": [
    "# prepare training set of NEGATIVE samples (similarity score == 1)\n",
    "bleurt_training_data_neg_samples = []\n",
    "\n",
    "for entry in bleurt_training_data: \n",
    "    claim = entry['claim']\n",
    "    reference = entry['reference']\n",
    "    \n",
    "    while True:\n",
    "        # randomly select target from another entry which is for a different claim \n",
    "        rand_entry = random.sample(bleurt_training_data, 1)[0]\n",
    "        if rand_entry['claim'] != claim:\n",
    "            break\n",
    "    \n",
    "    new_entry = POS_SAMPLE.copy()\n",
    "    new_entry['claim'] = claim\n",
    "    new_entry['reference'] = reference\n",
    "    new_entry['target'] = claim + \" \" + \" \".join(rand_entry[\"reference\"].split(\". \")[1:])\n",
    "    new_entry['score'] = 0\n",
    "    bleurt_training_data_neg_samples.append(new_entry)\n",
    "\n",
    "print(\"{} negative bleurt training samples created\".format(len(bleurt_training_data_neg_samples)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0005cafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19236\n"
     ]
    }
   ],
   "source": [
    "# Extend bleurt trianing data with negative samples\n",
    "bleurt_training_data.extend(bleurt_training_data_neg_samples)\n",
    "print(len(bleurt_training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "bfff5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save bleurt training data as jsonl file\n",
    "def to_dict(obj):\n",
    "    return json.loads(json.dumps(obj, default=lambda o: o.__dict__))\n",
    "\n",
    "def save_jsonl_file(data, file_path):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for entry in data:\n",
    "            json.dump(to_dict(entry), f)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "training_data_path = \"/Users/user/Library/CloudStorage/OneDrive-King'sCollegeLondon/PycharmProjects/fc-evidence-evaluation/data/reference_scorer_training_data\"\n",
    "\n",
    "save_jsonl_file(bleurt_training_data, os.path.join(training_data_path, \"fever_train_based.jsonl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5616df60",
   "metadata": {},
   "source": [
    "### Averitec data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "688b02cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load averitec training data\n",
    "train_path = \"/Users/user/Library/CloudStorage/OneDrive-King'sCollegeLondon/PycharmProjects/fc-evidence-evaluation/data/averitec/averitec_train.json\"\n",
    "train = utils.load_averitec_base(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d493c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AveritecEntry(claim='Hunter Biden had no experience in Ukraine or in the energy sector when he joined the board of Burisma.', label='Supported', justification='No former experience stated.', evidence=[AveritecQA(question='Did Hunter Biden have any experience in the energy sector at the time he joined the board of the  Burisma energy company in 2014', answers=[AveritecAnswer(answer='No', answer_type='Boolean', boolean_explanation=\"Hunter bidens previous career history does not include work for energy company's.\")]), AveritecQA(question='Did Hunter Biden have any experience in Ukraine at the time he joined the board of the  Burisma energy company in 2014', answers=[AveritecAnswer(answer='No', answer_type='Boolean', boolean_explanation=\"Hunter Bidens previous career history does not include working with Ukrainian company's.\")])])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9486b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "484c6f50",
   "metadata": {},
   "source": [
    "### Synthetic data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa844500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO later "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a089500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(sys.path[0] + \"/..\")\n",
    "\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86dbcf59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c447a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "_KEY = open('/Users/user/Desktop/openai_key.txt', 'r').read()\n",
    "_CLIENT = openai.OpenAI(\n",
    "    api_key=_KEY,\n",
    "    timeout=10,\n",
    ")\n",
    "_SEED = 10\n",
    "_MODEL = \"gpt-4\"\n",
    "_MAX_TOKENS = 1500\n",
    "\n",
    "_PROMPT = \"\"\"\n",
    "You will get a claim and evidence which SUPPORTS the claim. Your task is to adjust the evidence such that the evidence refutes what is stated in the claim. \n",
    "---\n",
    "Examples: \n",
    "claim: The Ten Commandments is an epic film.\n",
    "evidence: The Ten Commandments is a 1956 American biblical epic film produced , directed , and narrated by Cecil B. DeMille , shot in VistaVision -LRB- color by Technicolor -RRB- , and released by Paramount Pictures .\n",
    "adjusted evidence: The ten commandments were given to Moses by God, there exists no movie of such name.\n",
    "\n",
    "claim: Brad Pitt and his wife Angelina Jolie were a Hollywood couple.\n",
    "evidence: Angelina is divorced from actors Jonny Lee Miller, Billy Bob Thornton and Brad Pitt. She has six children with Pitt, three of whom were adopted internationally.\n",
    "adjusted evidence: Brad and Angelina are a happily married Hollywood couple that has six children, they never got divorced.\n",
    "---\n",
    "Please complete: \n",
    "claim: {}\n",
    "evidence: {}\n",
    "adjusted evidence:\"\"\"\n",
    "\n",
    "_PROMPT_REFORMULATION = \"\"\"\n",
    "You will get a claim and evidence which supports or refutes the claim. Your task is to adjust the evidence without changing its stance towards the claim. \n",
    "----\n",
    "Examples: \n",
    "claim: The Ten Commandments is an epic film.\n",
    "evidence: The Ten Commandments is a 1956 American biblical epic film produced , directed , and narrated by Cecil B. DeMille , shot in VistaVision -LRB- color by Technicolor -RRB- , and released by Paramount Pictures .\n",
    "adjusted evidence: The American movie Ten Commandments is an epic film.\n",
    "\n",
    "claim: Brad Pitt and his wife Angelina Jolie were a Hollywood couple.\n",
    "evidence: Angelina is divorced from actors Jonny Lee Miller, Billy Bob Thornton and Brad Pitt. She has six children with Pitt, three of whom were adopted internationally.\n",
    "adjusted evidence: Angelina is divorced from Pitt with whom she has six children, out of them three have been adopted\n",
    "----\n",
    "Please complete: \n",
    "claim: Selena recorded music.\n",
    "evidence: Selena signed with EMI Latin in 1989 and released her self-titled debut album the same year , while her brother became her principal music producer and songwriter .\n",
    "adjusted evidence:\"\"\"\n",
    "\n",
    "POS_SAMPLE = {\n",
    "    \"claim\": \"\",\n",
    "    \"reference\": \"\",\n",
    "    \"target\": \"\",\n",
    "    \"score\": 1,\n",
    "    \"label\": None\n",
    "}\n",
    "_EVIDENCE_FORMAT = \"Title: {}; {}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b8e08e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _query_openai(prompt: str, client, keys=None, seed=_SEED, model=_MODEL, max_tokens=_MAX_TOKENS,\n",
    "                  response_format=\"text\"):\n",
    "    return client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "        max_tokens=max_tokens,\n",
    "        response_format={\"type\": response_format},\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "def _get_response_text(response: openai.types.chat.chat_completion.ChatCompletion):\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def _get_wiki_evidence(wiki_id: str, sentence_idx: int): \n",
    "    entry = wiki_db[wiki_db.id==wiki_id]\n",
    "    sentences = list(entry.to_dict()[\"lines\"].values())[0]\n",
    "    sentence = sentences.split(\"\\n\")[sentence_idx]\n",
    "    return sentence.split(\"\\t\")[1]\n",
    "    \n",
    "\n",
    "def _get_evidence_text(evidence_set: list):\n",
    "    evidence_text = []\n",
    "    for evidence in evidence_set:\n",
    "        sentence = _get_wiki_evidence(evidence[2], evidence[3])\n",
    "        evidence_text.append(_EVIDENCE_FORMAT.format(evidence[2], sentence))\n",
    "        \n",
    "    return \" \".join(evidence_text)\n",
    "\n",
    "def _format_claim_evidence(claim, evidence_set):\n",
    "    return claim + \" \" + _get_evidence_text(evidence_set)\n",
    "\n",
    "def load_jsonl_file(file_path, dataclass=None):\n",
    "    content = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for entry in f.readlines():\n",
    "            if dataclass:\n",
    "                content.append(dacite.from_dict(data_class=dataclass, data=json.loads(entry)))\n",
    "            else:\n",
    "                content.append(json.loads(entry))\n",
    "    return content\n",
    "\n",
    "def _load_wiki_db(wiki_db_path = \"/Users/user/Downloads/wiki-pages/wiki-pages-jsons\"):\n",
    "    wiki_entries = {}\n",
    "    for file in os.listdir(wiki_db_path):\n",
    "        with open(os.path.join(wiki_db_path, file)) as f:\n",
    "            entry = json.load(f)\n",
    "            wiki_entries[entry['id']] = entry['lines']\n",
    "            \n",
    "    return wiki_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e446f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fever training data\n",
    "fever_train_path = \"/Users/user/Library/CloudStorage/OneDrive-King'sCollegeLondon/PycharmProjects/fc-evidence-evaluation/data/fever/paper_dev.jsonl\"\n",
    "train = load_jsonl_file(fever_train_path)\n",
    "\n",
    "# filter entries with more than one evidence set\n",
    "train_multi_evidence = [entry for entry in train if len(entry['evidence'])>1]\n",
    "train_multi_evidence_supports = [entry for entry in train_multi_evidence if entry['label']=='SUPPORTS']\n",
    "train_multi_evidence_refutes = [entry for entry in train_multi_evidence if entry['label']=='REFUTES']\n",
    "\n",
    "# Wikipedia db\n",
    "wiki_db = pd.read_csv(\"/Users/user/Downloads/wiki-pages/wiki-pages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "679b93b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_title_formatted(evidence_set):\n",
    "    return \"Title {}; \".format(evidence_set[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "633d8b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "917"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_multi_evidence_supports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b1b656d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over all fever samples\n",
    "bleurt_training_data = []\n",
    "\n",
    "for i, entry in enumerate(train_multi_evidence_supports):\n",
    "    try:\n",
    "        claim = entry['claim']\n",
    "        reference = _get_evidence_text(entry[\"evidence\"][0])\n",
    "        target = _get_evidence_text(entry[\"evidence\"][1])\n",
    "        if target != reference:\n",
    "            prompt = _PROMPT.format(claim, target)\n",
    "            adj_evidence = _get_response_text(_query_openai(prompt, _CLIENT))\n",
    "\n",
    "            new_entry = POS_SAMPLE.copy()\n",
    "            new_entry['claim'] = claim\n",
    "            new_entry['reference'] = claim + \" \" + reference\n",
    "            new_entry['target'] = claim + \" \" + _get_title_formatted(entry[\"evidence\"][1]) + adj_evidence\n",
    "            new_entry['score'] = 0\n",
    "\n",
    "            bleurt_training_data.append(new_entry)\n",
    "    except Exception as e:\n",
    "#         print(f\"i: {i}; e: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e1aa81be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bleurt_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "83a88801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save bleurt training data as jsonl file\n",
    "def to_dict(obj):\n",
    "    return json.loads(json.dumps(obj, default=lambda o: o.__dict__))\n",
    "\n",
    "def save_jsonl_file(data, file_path):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for entry in data:\n",
    "            json.dump(to_dict(entry), f)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "training_data_path = \"/Users/user/Library/CloudStorage/OneDrive-King'sCollegeLondon/PycharmProjects/fc-evidence-evaluation/data/reference_scorer_training_data\"\n",
    "\n",
    "save_jsonl_file(bleurt_training_data, os.path.join(training_data_path, \"fever_dev_gpt_score_zero.jsonl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38728aad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "124fa7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import string \n",
    "import pandas as pd \n",
    "\n",
    "from itertools import groupby\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b2be80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES\n",
    "SPLIT = \"dev\"\n",
    "\n",
    "PATH_FC = \"/Users/user/Library/CloudStorage/OneDrive-King'sCollegeLondon/PycharmProjects/fc-evidence-evaluation/data/vitaminc_factchecking/{}.jsonl\".format(SPLIT)\n",
    "PATH_REVISION = \"/Users/user/Library/CloudStorage/OneDrive-King'sCollegeLondon/PycharmProjects/fc-evidence-evaluation/data/vitaminc_flagging/{}.jsonl\".format(SPLIT)\n",
    "\n",
    "SAMPLE = {\n",
    "    \"claim\": \"\",\n",
    "    \"reference\": \"\",\n",
    "    \"target\": \"\",\n",
    "    \"score\": None,\n",
    "    \"label\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "42ef2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_file(file_path, dataclass=None):\n",
    "    content = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for entry in f.readlines():\n",
    "            if dataclass:\n",
    "                content.append(dacite.from_dict(data_class=dataclass, data=json.loads(entry)))\n",
    "            else:\n",
    "                content.append(json.loads(entry))\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d3208c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_data = load_jsonl_file(PATH_FC)\n",
    "fc_revision = load_jsonl_file(PATH_REVISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "23d6d214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>case_id</th>\n",
       "      <th>wiki_revision_id</th>\n",
       "      <th>label</th>\n",
       "      <th>claim</th>\n",
       "      <th>evidence</th>\n",
       "      <th>page</th>\n",
       "      <th>revision_type</th>\n",
       "      <th>FEVER_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ea2d97bc9e77c0009cda36d_1</td>\n",
       "      <td>5ea2d97bc9e77c0009cda36d</td>\n",
       "      <td>322052316</td>\n",
       "      <td>NOT ENOUGH INFO</td>\n",
       "      <td>Dragon Con had less than 1000 guests .</td>\n",
       "      <td>Among the more than 512 guests and musical per...</td>\n",
       "      <td>Dragon Con</td>\n",
       "      <td>real</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ea2d97bc9e77c0009cda36d_2</td>\n",
       "      <td>5ea2d97bc9e77c0009cda36d</td>\n",
       "      <td>322052316</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>Dragon Con had less than 1000 guests .</td>\n",
       "      <td>Among the more than 6000 guests and musical pe...</td>\n",
       "      <td>Dragon Con</td>\n",
       "      <td>real</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5ea2d97bc9e77c0009cda36d_3</td>\n",
       "      <td>5ea2d97bc9e77c0009cda36d</td>\n",
       "      <td>322052316</td>\n",
       "      <td>NOT ENOUGH INFO</td>\n",
       "      <td>Dragon Con had over 5000 guests .</td>\n",
       "      <td>Among the more than 512 guests and musical per...</td>\n",
       "      <td>Dragon Con</td>\n",
       "      <td>real</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    unique_id                   case_id wiki_revision_id  \\\n",
       "0  5ea2d97bc9e77c0009cda36d_1  5ea2d97bc9e77c0009cda36d        322052316   \n",
       "1  5ea2d97bc9e77c0009cda36d_2  5ea2d97bc9e77c0009cda36d        322052316   \n",
       "2  5ea2d97bc9e77c0009cda36d_3  5ea2d97bc9e77c0009cda36d        322052316   \n",
       "\n",
       "             label                                   claim  \\\n",
       "0  NOT ENOUGH INFO  Dragon Con had less than 1000 guests .   \n",
       "1          REFUTES  Dragon Con had less than 1000 guests .   \n",
       "2  NOT ENOUGH INFO       Dragon Con had over 5000 guests .   \n",
       "\n",
       "                                            evidence        page  \\\n",
       "0  Among the more than 512 guests and musical per...  Dragon Con   \n",
       "1  Among the more than 6000 guests and musical pe...  Dragon Con   \n",
       "2  Among the more than 512 guests and musical per...  Dragon Con   \n",
       "\n",
       "  revision_type FEVER_id  \n",
       "0          real      NaN  \n",
       "1          real      NaN  \n",
       "2          real      NaN  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fc_data = pd.DataFrame.from_dict(fc_data)\n",
    "\n",
    "df_fc_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8006529a",
   "metadata": {},
   "source": [
    "### Create examples with score==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "96911e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by multiple evidence \n",
    "fc_data_sorted = sorted(fc_data, key = itemgetter('claim'))\n",
    "fc_data_grouped = groupby(fc_data_sorted, key = itemgetter('claim'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "9eb8e829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ 16 million was the film budget of Varsity Blues ( film ) .\n",
      "<itertools._grouper object at 0x7fbdb10f5bb0>\n",
      "<itertools._grouper object at 0x7fbdb10f5bb0>\n"
     ]
    }
   ],
   "source": [
    "for key, value in groupby(fc_data_sorted, key = itemgetter('claim')):\n",
    "    print(key)\n",
    "    for v in value:\n",
    "        print(value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "eba1542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_dataset_sample(ref_entry, target_entry, score):\n",
    "    entry_output = SAMPLE.copy()\n",
    "    entry_output['claim'] = target_entry['claim']\n",
    "    entry_output['reference'] = \"{} {}\".format(target_entry['claim'], ref_entry['evidence'])\n",
    "    entry_output['target'] = \"{} {}\".format(target_entry['claim'], target_entry['evidence'])\n",
    "    entry_output['score'] = score\n",
    "    entry_output['label'] = target_entry['label']\n",
    "    \n",
    "    return entry_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "1ffea318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31408"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def key_func(k):\n",
    "    return k['claim']\n",
    "\n",
    "i = 0\n",
    "ds_samples_score0 = []\n",
    "fc_data_sorted = sorted(fc_data, key = key_func)\n",
    "\n",
    "for key, values in groupby(fc_data_sorted, key_func):        \n",
    "    first_value = None\n",
    "    for value in values:\n",
    "        if not first_value: \n",
    "            first_value = value\n",
    "            continue\n",
    "        if value['label'] == first_value['label']:\n",
    "            continue\n",
    "        # only entries with different evidence such that label flips \n",
    "        ds_samples_score0.append(map_dataset_sample(first_value, value, score=0))\n",
    "\n",
    "len(ds_samples_score0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0da61591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_samples_score0[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab09d64",
   "metadata": {},
   "source": [
    "### Create examples with score == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "41a1fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_chars = [\n",
    "    \",\",\n",
    "    \".\",\n",
    "    \"(\",\n",
    "    \")\",\n",
    "    \"'\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "fe71a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_whitespace(sent: str):\n",
    "    for char in special_chars: \n",
    "        sent = sent.replace(char, \" {} \".format(char)).replace(\"  \", \" \")\n",
    "    print(sent+\"\\n\")\n",
    "    return sent\n",
    "\n",
    "def remove_spec_chars(sent: str):\n",
    "    sent = re.sub(r\"[^ a-zA-Z0-9]+\",'', sent)\n",
    "    return re.sub(' +', ' ', sent).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b3971e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_in_fc_data(evidence_sent, df): \n",
    "    evidence_sent = remove_spec_chars(evidence_sent)\n",
    "    if evidence_sent in list(df['evidence_no_spec_chars']):\n",
    "        return df.loc[df['evidence_no_spec_chars']==evidence_sent]\n",
    "        \n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ef6b67fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_dataset_sample_revision(fc_entry, revision_sent_a, revision_sent_b, score):\n",
    "    fc_entry = pd.DataFrame(fc_entry)\n",
    "#     print(fc_entry)\n",
    "    \n",
    "    mapped_entries = []\n",
    "    for i, row in fc_entry.iterrows():\n",
    "        entry_output = SAMPLE.copy()\n",
    "        entry_output['claim'] = row['claim']\n",
    "        entry_output['reference'] = \"{} {}\".format(row['claim'], revision_sent_a)\n",
    "        entry_output['target'] = \"{} {}\".format(row['claim'], revision_sent_b)\n",
    "        entry_output['score'] = score\n",
    "        entry_output['label'] = row['label']\n",
    "        # add to output list\n",
    "        mapped_entries.append(entry_output)\n",
    "    \n",
    "    return mapped_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "26227703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove spec chars to allow mapping\n",
    "df_fc_data['evidence_no_spec_chars'] = df_fc_data['evidence'].apply(remove_spec_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35bd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22970 non-factual revisions out of 36624\n"
     ]
    }
   ],
   "source": [
    "# exmaples with non-factual changes\n",
    "fc_revision_non_fact = [entry for entry in fc_revision if entry['label']=='not factual']\n",
    "print(\"{} non-factual revisions out of {}\".format(len(fc_revision_non_fact), len(fc_revision)))\n",
    "\n",
    "ds_samples_score1 = []\n",
    "for entry in fc_revision_non_fact:\n",
    "    try:\n",
    "        # find sentence a or b in fc_data\n",
    "        match = find_in_fc_data(entry['sent_a'], df_fc_data)\n",
    "        if len(match) == 0:\n",
    "            match = find_in_fc_data(entry['sent_b'], df_fc_data)\n",
    "\n",
    "        if len(match) > 0:\n",
    "            # create example\n",
    "            ds_samples_score1.append(map_dataset_sample_revision(match, entry['sent_a'], entry['sent_b'], score=1))\n",
    "    except Exception as e: \n",
    "        print(\"Exception: {}\".format(e))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453a328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds_samples_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c5769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_samples = ds_samples_score0 + ds_samples_score1\n",
    "len(ds_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe930b1",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a8627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict(obj):\n",
    "    return json.loads(json.dumps(obj, default=lambda o: o.__dict__))\n",
    "\n",
    "def save_jsonl_file(data, file_path):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for entry in data:\n",
    "            json.dump(to_dict(entry), f)\n",
    "            f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dbb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/Users/user/Library/CloudStorage/OneDrive-King'sCollegeLondon/PycharmProjects/fc-evidence-evaluation/data/reference_scorer_training_data/vitaminc_{}.jsonl\".format(SPLIT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9bc13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_jsonl_file(ds_samples, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd9f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe5c09b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

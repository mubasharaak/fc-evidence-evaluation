{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ca2efb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import string \n",
    "import pandas as pd \n",
    "\n",
    "from itertools import groupby\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3bceb88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES\n",
    "SPLIT = \"train\"\n",
    "\n",
    "PATH_FC = \"/Users/user/Library/CloudStorage/OneDrive-King'sCollegeLondon/PycharmProjects/fc-evidence-evaluation/data/vitaminc_factchecking/{}.jsonl\".format(SPLIT)\n",
    "PATH_REVISION = \"/Users/user/Library/CloudStorage/OneDrive-King'sCollegeLondon/PycharmProjects/fc-evidence-evaluation/data/vitaminc_flagging/{}.jsonl\".format(SPLIT)\n",
    "\n",
    "SAMPLE = {\n",
    "    \"claim\": \"\",\n",
    "    \"reference\": \"\",\n",
    "    \"target\": \"\",\n",
    "    \"score\": None,\n",
    "    \"label\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c42e2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_file(file_path, dataclass=None):\n",
    "    content = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for entry in f.readlines():\n",
    "            if dataclass:\n",
    "                content.append(dacite.from_dict(data_class=dataclass, data=json.loads(entry)))\n",
    "            else:\n",
    "                content.append(json.loads(entry))\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "db126718",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_data = load_jsonl_file(PATH_FC)\n",
    "fc_revision = load_jsonl_file(PATH_REVISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b339bd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>case_id</th>\n",
       "      <th>wiki_revision_id</th>\n",
       "      <th>label</th>\n",
       "      <th>claim</th>\n",
       "      <th>evidence</th>\n",
       "      <th>page</th>\n",
       "      <th>revision_type</th>\n",
       "      <th>FEVER_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ec5598dc9e77c000842c3cd_1</td>\n",
       "      <td>5ec5598dc9e77c000842c3cd</td>\n",
       "      <td>925488060</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>Manchester had a population of more than 540,0...</td>\n",
       "      <td>Manchester ( ) is a major city and metropolita...</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>real</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ec5598dc9e77c000842c3cd_2</td>\n",
       "      <td>5ec5598dc9e77c000842c3cd</td>\n",
       "      <td>925488060</td>\n",
       "      <td>NOT ENOUGH INFO</td>\n",
       "      <td>Manchester had a population of more than 540,0...</td>\n",
       "      <td>Manchester ( ) is a major city and metropolita...</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>real</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5ec5598dc9e77c000842c3cd_3</td>\n",
       "      <td>5ec5598dc9e77c000842c3cd</td>\n",
       "      <td>925488060</td>\n",
       "      <td>NOT ENOUGH INFO</td>\n",
       "      <td>Manchester had a population of less than 540,0...</td>\n",
       "      <td>Manchester ( ) is a major city and metropolita...</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>real</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    unique_id                   case_id wiki_revision_id  \\\n",
       "0  5ec5598dc9e77c000842c3cd_1  5ec5598dc9e77c000842c3cd        925488060   \n",
       "1  5ec5598dc9e77c000842c3cd_2  5ec5598dc9e77c000842c3cd        925488060   \n",
       "2  5ec5598dc9e77c000842c3cd_3  5ec5598dc9e77c000842c3cd        925488060   \n",
       "\n",
       "             label                                              claim  \\\n",
       "0         SUPPORTS  Manchester had a population of more than 540,0...   \n",
       "1  NOT ENOUGH INFO  Manchester had a population of more than 540,0...   \n",
       "2  NOT ENOUGH INFO  Manchester had a population of less than 540,0...   \n",
       "\n",
       "                                            evidence        page  \\\n",
       "0  Manchester ( ) is a major city and metropolita...  Manchester   \n",
       "1  Manchester ( ) is a major city and metropolita...  Manchester   \n",
       "2  Manchester ( ) is a major city and metropolita...  Manchester   \n",
       "\n",
       "  revision_type FEVER_id  \n",
       "0          real      NaN  \n",
       "1          real      NaN  \n",
       "2          real      NaN  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fc_data = pd.DataFrame.from_dict(fc_data)\n",
    "\n",
    "df_fc_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77879320",
   "metadata": {},
   "source": [
    "### Create examples with score==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "1c6a4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by multiple evidence \n",
    "fc_data_sorted = sorted(fc_data, key = itemgetter('claim'))\n",
    "fc_data_grouped = groupby(fc_data_sorted, key = itemgetter('claim'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "efe89e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! n 1999 , Portia de Rossi was the winner of a Golden Globe Award .\n",
      "<itertools._grouper object at 0x7fbdb1114820>\n",
      "<itertools._grouper object at 0x7fbdb1114820>\n"
     ]
    }
   ],
   "source": [
    "for key, value in groupby(fc_data_sorted, key = itemgetter('claim')):\n",
    "    print(key)\n",
    "    for v in value:\n",
    "        print(value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b44faf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_dataset_sample(ref_entry, target_entry, score):\n",
    "    entry_output = SAMPLE.copy()\n",
    "    entry_output['claim'] = target_entry['claim']\n",
    "    entry_output['reference'] = \"{} {}\".format(target_entry['claim'], ref_entry['evidence'])\n",
    "    entry_output['target'] = \"{} {}\".format(target_entry['claim'], target_entry['evidence'])\n",
    "    entry_output['score'] = score\n",
    "    entry_output['label'] = target_entry['label']\n",
    "    \n",
    "    return entry_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a1c2299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184802"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def key_func(k):\n",
    "    return k['claim']\n",
    "\n",
    "i = 0\n",
    "ds_samples_score0 = []\n",
    "fc_data_sorted = sorted(fc_data, key = key_func)\n",
    "\n",
    "for key, values in groupby(fc_data_sorted, key_func):        \n",
    "    first_value = None\n",
    "    for value in values:\n",
    "        if not first_value: \n",
    "            first_value = value\n",
    "            continue\n",
    "        if value['label'] == first_value['label']:\n",
    "            continue\n",
    "        # only entries with different evidence such that label flips \n",
    "        ds_samples_score0.append(map_dataset_sample(first_value, value, score=0))\n",
    "\n",
    "len(ds_samples_score0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8f18af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_samples_score0[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd956de9",
   "metadata": {},
   "source": [
    "### Create examples with score == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "137a8dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_chars = [\n",
    "    \",\",\n",
    "    \".\",\n",
    "    \"(\",\n",
    "    \")\",\n",
    "    \"'\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "6105593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_whitespace(sent: str):\n",
    "    for char in special_chars: \n",
    "        sent = sent.replace(char, \" {} \".format(char)).replace(\"  \", \" \")\n",
    "    print(sent+\"\\n\")\n",
    "    return sent\n",
    "\n",
    "def remove_spec_chars(sent: str):\n",
    "    sent = re.sub(r\"[^ a-zA-Z0-9]+\",'', sent)\n",
    "    return re.sub(' +', ' ', sent).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "918f6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_in_fc_data(evidence_sent, df): \n",
    "    evidence_sent = remove_spec_chars(evidence_sent)\n",
    "    if evidence_sent in list(df['evidence_no_spec_chars']):\n",
    "        return df.loc[df['evidence_no_spec_chars']==evidence_sent]\n",
    "        \n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5c2f0431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_dataset_sample_revision(fc_entry, revision_sent_a, revision_sent_b, score):\n",
    "    fc_entry = pd.DataFrame(fc_entry)\n",
    "#     print(fc_entry)\n",
    "    \n",
    "    mapped_entries = []\n",
    "    for i, row in fc_entry.iterrows():\n",
    "        entry_output = SAMPLE.copy()\n",
    "        entry_output['claim'] = row['claim']\n",
    "        entry_output['reference'] = \"{} {}\".format(row['claim'], revision_sent_a)\n",
    "        entry_output['target'] = \"{} {}\".format(row['claim'], revision_sent_b)\n",
    "        entry_output['score'] = score\n",
    "        entry_output['label'] = row['label']\n",
    "        # add to output list\n",
    "        mapped_entries.append(entry_output)\n",
    "    \n",
    "    return mapped_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "58b3300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove spec chars to allow mapping\n",
    "df_fc_data['evidence_no_spec_chars'] = df_fc_data['evidence'].apply(remove_spec_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "edee3b62",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154914 non-factual revisions out of 236998\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x7/b6tgwcrn1rz_zffbw59v8crr0000gp/T/ipykernel_75575/3742165882.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_in_fc_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sent_a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_fc_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_in_fc_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sent_b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_fc_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/x7/b6tgwcrn1rz_zffbw59v8crr0000gp/T/ipykernel_75575/3165420529.py\u001b[0m in \u001b[0;36mfind_in_fc_data\u001b[0;34m(evidence_sent, df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_in_fc_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevidence_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mevidence_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_spec_chars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevidence_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mevidence_sent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'evidence_no_spec_chars'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'evidence_no_spec_chars'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mevidence_sent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# exmaples with non-factual changes\n",
    "fc_revision_non_fact = [entry for entry in fc_revision if entry['label']=='not factual']\n",
    "print(\"{} non-factual revisions out of {}\".format(len(fc_revision_non_fact), len(fc_revision)))\n",
    "\n",
    "ds_samples_score1 = []\n",
    "for entry in fc_revision_non_fact:\n",
    "    try:\n",
    "        # find sentence a or b in fc_data\n",
    "        match = find_in_fc_data(entry['sent_a'], df_fc_data)\n",
    "        if len(match) == 0:\n",
    "            match = find_in_fc_data(entry['sent_b'], df_fc_data)\n",
    "\n",
    "        if len(match) > 0:\n",
    "            # create example\n",
    "            ds_samples_score1.append(map_dataset_sample_revision(match, entry['sent_a'], entry['sent_b'], score=1))\n",
    "    except Exception as e: \n",
    "        print(\"Exception: {}\".format(e))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b6f2f3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13455"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_samples_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b76f8421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198257"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_samples = ds_samples_score0 + ds_samples_score1\n",
    "len(ds_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c76d6d",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "69d4fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict(obj):\n",
    "    return json.loads(json.dumps(obj, default=lambda o: o.__dict__))\n",
    "\n",
    "def save_jsonl_file(data, file_path):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for entry in data:\n",
    "            json.dump(to_dict(entry), f)\n",
    "            f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5896fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/Users/user/Library/CloudStorage/OneDrive-King'sCollegeLondon/PycharmProjects/fc-evidence-evaluation/data/reference_scorer_training_data/vitaminc_{}.jsonl\".format(SPLIT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "89779170",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_jsonl_file(ds_samples, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f026b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5ca63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
